---
output:
  md_document:
    variant: markdown_github
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
library(dplyr)
```

# vapour

The goal of vapour is to provide a basic **GDAL API** package for R. Ideally, this could become a common foundation for other packages to specialize. A parallel goal is to be freed from the powerful but sometimes limiting high-level data models of GDAL itself, specifically these are *simple features* and *affine-based regular rasters composed of 2D slices*. (GDAL will possibly remove these limitations over time but still there will always be value in having modularity in an ecosystem of tools. )

Currently all it does is read vector data attributes or geometry.  This is inspired by and draws heavily on work done [the sf package, simple features for R and rgdal and rgdal2](https://github.com/r-spatial/sf). 

Big thanks to Edzer Pebesma and Roger Bivand for prior art that I crib and copy from. 




## Examples

There's a function `vapour_read_attributes` that returns the attributes as  list of vectors. 

```{r}
pfile <- system.file("extdata", "point.shp", package = "vapour")
library(vapour)
vapour_read_attributes(pfile)
```

A higher level function `read_gdal_attribute` wraps that function to return a data frame. 

```{r}
sfile <- system.file("shape/nc.shp", package="sf")

read_gdal_table(sfile)
```

There are many useful higher level operations that can be used with this. The simplest is the ability to use GDAL as a database-like connection to attribute tables. 

A low-level function will return a character vector of JSON, GML, KML or WKT. 

```{r}
vapour_read_geometry(pfile)[5:6]  ## format = "WKB"

vapour_read_geometry_text(pfile)[5:6]  ## format = "json"

sfile <- system.file("shape/nc.shp", package="sf")

vapour_read_geometry_text(sfile, format = "gml")[99:100]

vapour_read_geometry_text(sfile, format = "kml")[1:2]
```


We can combine these together to get a custom data set. 

```{r}
library(dplyr)
dat <- read_gdal_table(sfile) %>% dplyr::mutate(kml = vapour_read_geometry_text(sfile, format = "kml"))
glimpse(dat)
```

## Fast summary 

There is a basic function `vapour_read_extent` to return a straight forward bounding box vector for every feature, so that
we can flexibly build an index of a data set for later use. 

```{r}
sfile <- system.file("shape/nc.shp", package="sf")
str(vapour_read_extent(sfile))

```

This makes for a very lightweight summary data set that will scale to hundreds of large inputs. 

```{r}
dat <- read_gdal_table(sfile)
library(raster)
dat$bbox <- vapour_read_extent(sfile)

plot(purrr::reduce(lapply(dat$bbox, raster::extent), raster::union))
purrr::walk(lapply(dat$bbox, raster::extent), plot, add = TRUE)

```

An example is this set of 29 property boundary shapefiles, read into a few hundred Mb of simple features. 

```{r}
library(dplyr)
files <- raadfiles::thelist_files(format = "") %>% filter(grepl("parcel", fullname), grepl("shp$", fullname))
library(vapour)
system.time(purrr::map(files$fullname, sf::read_sf))
library(blob)

## our timing is competitive, and we get to choose what is read
## and when
system.time({
d <- purrr::map(files$fullname, read_gdal_table)
d <- dplyr::bind_rows(d)
g <- purrr::map(files$fullname, read_gdal_geometry)
d[["wkb"]] <- new_blob(unlist(g, recursive = FALSE))
})

```

We can read that in this simpler way for a quick data set to act as an index. 

```{r}
system.time({
  d <- purrr::map_df(files$fullname, read_gdal_table)
  d$bbox <- unlist(purrr::map(files$fullname, vapour_read_extent), recursive = FALSE)
})

pryr::object_size(d)
glimpse(d)

```


## Set up

I've kept a record of a minimal GDAL wrapper package here: 

https://github.com/mdsumner/gdalmin

This must be run when your function definitions change: 

```R
tools::package_native_routine_registration_skeleton("../vapour", "src/init.c",character_only = FALSE)
```



# Code of conduct

Please note that this project is released with a [Contributor Code of Conduct](CONDUCT.md). By participating in this project you agree to abide by its terms.
